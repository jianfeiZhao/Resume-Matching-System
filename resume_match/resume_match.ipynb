{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resume_match.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvfKJiFJPkHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "561ebec9-9cab-46b9-c813-2107ba4d87ad"
      },
      "source": [
        "!pip install pyspark\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G9Yj7TCHHCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# load data\n",
        "#df = pd.read_csv('./jobs_small.csv', encoding=\"latin-1\")\n",
        "df = pd.read_csv('./jobs.csv', encoding=\"utf-8\")\n",
        "#print(df.head())\n",
        "\n",
        "# text preprocessing\n",
        "REPLACE_BY_SPACE_RE = re.compile('[#+_/(){}!^?<>\"''*\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "match_regex = re.compile('\\d+')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "# data cleaning\n",
        "def clean_text(text):\n",
        "    # change to lower-csae\n",
        "    text = str(text).lower()\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "    # remove BAD_SYMBOLS_RE\n",
        "    text = BAD_SYMBOLS_RE.sub('', text)\n",
        "    text = match_regex.sub('', text)\n",
        "    # drop the stopwords\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
        "    return text\n",
        "\n",
        "# read and clean the resume file\n",
        "f = open('./CE.txt', 'r')          ############# change resume here ####################\n",
        "text = f.read()\n",
        "text = clean_text(text)\n",
        "\n",
        "# clean the desc field\n",
        "df['desc_clean'] = df['description'].apply(clean_text)\n",
        "df.drop(columns=['description', 'id'], inplace=True)\n",
        "df.loc[0] = ['resume', 0, 0, 0, text]\n",
        "\n",
        "for i in range(len(df)):\n",
        "  try:\n",
        "    if df['desc_clean'][i]=='nan' or df['desc_clean'][i]=='' or len(df['desc_clean'][i]) < 100:\n",
        "      df.drop(labels=i, inplace=True)\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "df.dropna(axis=0, inplace=True)\n",
        "df['id'] = [i for i in range(len(df))]\n",
        "#print(df['desc_clean'])\n",
        "df.to_csv('./jobs_clean.csv')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x0T-83svJ_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "486d7e02-6331-423a-f18e-a2a87e766dea"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "#from pyspark.ml.feature import NGram\n",
        "\n",
        "spark=SparkSession \\\n",
        "        .builder \\\n",
        "        .appName('tfidf_app') \\\n",
        "        .getOrCreate()\n",
        "\n",
        "# load data\n",
        "df0 = spark.read.csv(\"./jobs_clean.csv\", header=True, multiLine=True, inferSchema=True)\n",
        "df1 = pd.read_csv('./jobs_clean.csv')\n",
        "#df0.show()\n",
        "print('The number of jobs：',df0.count())\n",
        "print('\\nthe distinct jobs name: ', df1.job.unique())\n",
        "print('\\nThere are', len(df1.job.unique())-1, 'different kinds of jobs in the table.')\n",
        "\n",
        "# split the desc field\n",
        "tokenizer = Tokenizer(inputCol='desc_clean', outputCol='desc_words')\n",
        "df = tokenizer.transform(df0)\n",
        "#df.show()\n",
        "#df.select('desc_words').show(10)\n",
        "\n",
        "# compute TF-IDF\n",
        "hashingTF = HashingTF(inputCol='desc_words', outputCol='desc_words_tf')\n",
        "tf = hashingTF.transform(df).cache()\n",
        "idf = IDF(inputCol='desc_words_tf', outputCol='desc_words_tfidf').fit(tf)\n",
        "tfidf = idf.transform(tf).cache()\n",
        "#print('tfidf for each job:', tfidf.select('desc_words_tfidf').show(10,truncate=False))\n",
        "\n",
        "# data normalization\n",
        "from pyspark.ml.feature import Normalizer\n",
        "normalizer = Normalizer(inputCol=\"desc_words_tfidf\", outputCol=\"norm\")\n",
        "tfidf = normalizer.transform(tfidf)\n",
        "#tfidf.select(\"id\", \"norm\").show(6)\n",
        "\n",
        "# compute similarity between jobs and resume\n",
        "import pyspark.sql.functions as psf \n",
        "from pyspark.sql.types import DoubleType\n",
        "print('\\nCompute the similarity between jobs and resume...')\n",
        "dot_udf = psf.udf(lambda x,y: float(x.dot(y)), DoubleType()) # define dot-product function\n",
        "tfidf = tfidf.alias(\"a1\").join(tfidf.alias(\"a2\"), psf.col(\"a1.id\") == 0)\\\n",
        "        .select(\n",
        "            psf.col(\"a1.job\"),\n",
        "            psf.col(\"a1.id\").alias(\"id1\"), \n",
        "            psf.col(\"a2.id\").alias(\"id2\"), \n",
        "            dot_udf(\"a1.norm\", \"a2.norm\").alias(\"similarity\"))\n",
        "#tfidf.show(10)\n",
        "print('Done!')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of jobs： 14791\n",
            "\n",
            "the distinct jobs name:  ['resume' 'data-scientist' 'software-developer' 'statistician'\n",
            " 'IT manager' 'web developer' 'database administrator'\n",
            " 'information security analyst' 'computer systems analyst'\n",
            " 'computer network architect' 'computer support specialist'\n",
            " 'Circuit Design Engineer' 'FPGA Engineer' 'Embedded Systems Engineer'\n",
            " 'Electrical Design Engineer' 'Telecommunications Engineer'\n",
            " 'Machine Learning Engineer' 'python' 'software engineer'\n",
            " 'Java Software Engineer' 'Python Software Engineer'\n",
            " 'Golang Software Engineer' 'PHP developer' 'Node js developer'\n",
            " 'Ruby developer' 'Front End Web Developer' 'SQL Developer'\n",
            " 'flash Developer' 'JavaScript Developer' 'Android Developer'\n",
            " 'IOS Developer' 'Database Engineer' 'Spark Engineer' 'Data Analyst'\n",
            " 'electrical test' 'Performance Test Engineer' 'Test Automation Engineer'\n",
            " 'PLC Technician' 'DSP engineer' 'ARM engineer' 'NLP engineer'\n",
            " 'computer vision engineer' 'Operations Technician'\n",
            " 'Software Product Manager' 'Architect']\n",
            "\n",
            "There are 44 different kinds of jobs in the table.\n",
            "\n",
            "Compute the similarity between jobs and resume...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXO-Isbk6Uj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "b89a8d19-0b01-43ea-805e-14aa0712e6a5"
      },
      "source": [
        "# show Top-20 matched jobs\n",
        "match = tfidf.where('id1 = 0').sort('similarity', ascending=False).where('id2 > 0')\n",
        "top_match = match.limit(20)\n",
        "print('Top 20 matched jobs:')\n",
        "df0.alias(\"a1\").join(top_match.alias(\"a2\"), psf.col(\"a1.id\") == psf.col(\"a2.id2\"))\\\n",
        "    .select(psf.col(\"a1.job\"), \"a1.company\", \"a1.location\", \"a2.similarity\")\\\n",
        "    .sort('similarity', ascending=False).show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 20 matched jobs:\n",
            "+--------------------+--------------------+--------------------+-------------------+\n",
            "|                 job|             company|            location|         similarity|\n",
            "+--------------------+--------------------+--------------------+-------------------+\n",
            "|        NLP engineer|         Axiom Group|       Austin, Texas| 0.1887218973121401|\n",
            "|      data-scientist|      KR Elixir, Inc|San Francisco, Ca...| 0.1818072658180541|\n",
            "|        NLP engineer| Tailored Management|South San Francis...|0.18022456541360377|\n",
            "|Machine Learning ...|         CyberCoders|San Francisco, Ca...|0.16317681882956594|\n",
            "|        NLP engineer|Whitney, Bradley ...|Crystal City, Vir...|0.15284096175042325|\n",
            "|        NLP engineer|     PayPal Holdings|San Jose, Califor...|0.15275969005591425|\n",
            "|      Spark Engineer|     PayPal Holdings|San Jose, Califor...|0.15275969005591425|\n",
            "|        NLP engineer|              Leidos|Washington, Distr...| 0.1505508492704159|\n",
            "|Python Software E...|IVYSYS TECHNOLOGI...|McLean/Arlington,...|0.15054672037557446|\n",
            "|   Database Engineer|IVYSYS TECHNOLOGI...|McLean/Arlington,...|0.15054672037557446|\n",
            "|        NLP engineer|IVYSYS TECHNOLOGI...|McLean/Arlington,...|0.15054672037557446|\n",
            "|        NLP engineer|              Leidos|Washington, Distr...|0.15048498202509134|\n",
            "|        NLP engineer|              Leidos|Washington, Distr...|0.14989178066188832|\n",
            "|       FPGA Engineer|            SPECTRUM|      Pine, Colorado| 0.1482500676731241|\n",
            "|Machine Learning ...|            SPECTRUM|Wheat Ridge, Colo...| 0.1482500676731241|\n",
            "|      data-scientist|            SPECTRUM|    Golden, Colorado| 0.1482500676731241|\n",
            "|      Spark Engineer|            SPECTRUM| Englewood, Colorado| 0.1482500676731241|\n",
            "|        NLP engineer|            SPECTRUM| Englewood, Colorado| 0.1482500676731241|\n",
            "|      data-scientist|              Encore|Hartford, Connect...| 0.1478482451664877|\n",
            "|Machine Learning ...|              Encore|Hartford, Connect...| 0.1478482451664877|\n",
            "+--------------------+--------------------+--------------------+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9VpHzNJigQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "match = df0.alias(\"a1\").join(match.alias(\"a2\"), psf.col(\"a1.id\") == psf.col(\"a2.id2\"))\\\n",
        "    .select(psf.col(\"a1.job\"), \"a1.company\", \"a1.location\", \"a2.similarity\")\\\n",
        "    .sort('similarity', ascending=False)\n",
        "\n",
        "# create SQL table\n",
        "match.createOrReplaceTempView(\"match\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSfKy7g3n3ez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "8a1bbf5f-724f-4dfa-ae67-9fc85a51352d"
      },
      "source": [
        "# start SQL query\n",
        "\n",
        "# select jobs in specific location\n",
        "df = spark.sql(\"SELECT * FROM match WHERE location like 'New York City%'\")\n",
        "#df = spark.sql(\"SELECT * FROM match WHERE location like 'San Francisco%'\")\n",
        "df.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                 job|             company|            location|          similarity|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|Telecommunication...|      Clarapath Inc.|New York City, Ne...| 0.04988706287672642|\n",
            "|       FPGA Engineer|      Clarapath Inc.|New York City, Ne...| 0.04988706287672642|\n",
            "|              python|           Synechron|New York City, Ne...|0.035548372632214956|\n",
            "|Telecommunication...|      Clarapath Inc.|New York City, Ne...|0.034945310902609356|\n",
            "|       web developer|      Clarapath Inc.|New York City, Ne...|0.034945310902609356|\n",
            "|   Database Engineer|           Synechron|New York City, Ne...| 0.03454556273853086|\n",
            "|Python Software E...|           Synechron|New York City, Ne...| 0.03454556273853086|\n",
            "|           Architect|           Synechron|New York City, Ne...| 0.03454556273853086|\n",
            "|Software Product ...|        Technovision|New York City, Ne...| 0.03115421079601298|\n",
            "|database administ...|Business Informat...|New York City, Ne...|0.029346975702960926|\n",
            "|Test Automation E...|Park Hudson Inter...|New York City, Ne...|0.027419386578140224|\n",
            "|        DSP engineer|          CloudFlare|New York City, Ne...| 0.02657937467733803|\n",
            "|      data-scientist|                Grow|New York City, Ne...|0.023481358658936607|\n",
            "|Machine Learning ...|                Grow|New York City, Ne...|0.023481358658936607|\n",
            "|      Spark Engineer|        Apex Systems|New York City, Ne...|0.021909819169386807|\n",
            "|      data-scientist| The NPD Group, Inc.|New York City, Ne...|0.020684520483680347|\n",
            "|Java Software Eng...|            Data Inc|New York City, Ne...| 0.02004689255561453|\n",
            "|        Data Analyst|GRANT PETERS ASSO...|New York City, Ne...|0.019200753034171885|\n",
            "|JavaScript Developer|    Case Interactive|New York City, Ne...| 0.01902748198912478|\n",
            "|Python Software E...|    Case Interactive|New York City, Ne...| 0.01902748198912478|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLmUQOV-wD2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "73237c2e-8e9a-4407-d1d4-432ce2a43d2e"
      },
      "source": [
        "#select specific jobs\n",
        "#df = spark.sql(\"SELECT * FROM match where job = 'computer vision engineer'\")\n",
        "#df = spark.sql(\"SELECT * FROM match where job = 'FPGA Engineer'\")\n",
        "df = spark.sql(\"SELECT * FROM match where job = 'Embedded Systems Engineer'\")\n",
        "\n",
        "df.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+-------------------+\n",
            "|                 job|             company|            location|         similarity|\n",
            "+--------------------+--------------------+--------------------+-------------------+\n",
            "|Embedded Systems ...|Southwest Researc...|  San Antonio, Texas|0.11408710602803729|\n",
            "|Embedded Systems ...|US ARMY Ground Ve...|WARREN, Michigan ...|0.10491342174520059|\n",
            "|Embedded Systems ...|              Abbott| Alameda, California|0.09937305121916463|\n",
            "|Embedded Systems ...|           Talentlab|          OTTAWA, ON|0.09733485801632007|\n",
            "|Embedded Systems ...|        Oculii Corp.|Beavercreek, Ohio...| 0.0955485982066785|\n",
            "|Embedded Systems ...|       Kumu Networks|Sunnyvale, Califo...| 0.0954019401067412|\n",
            "|Embedded Systems ...|      D3 Engineering|Rochester, New Yo...|0.09532752286044031|\n",
            "|Embedded Systems ...|  NVIDIA Corporation|Santa Clara, Cali...|0.09069194568483023|\n",
            "|Embedded Systems ...|         CyberCoders|  San Antonio, Texas|0.08739002114928836|\n",
            "|Embedded Systems ...|Southwest Researc...|  San Antonio, Texas|0.08734039335372538|\n",
            "|Embedded Systems ...|          Neteffects|Creve Coeur, Miss...| 0.0839969616373131|\n",
            "|Embedded Systems ...|             Novanta|North Syracuse, N...|0.08396024753874272|\n",
            "|Embedded Systems ...|         CyberCoders|Hayward, Californ...| 0.0820860831573231|\n",
            "|Embedded Systems ...|         CyberCoders|Colorado Springs,...|0.08191617468147264|\n",
            "|Embedded Systems ...|IntelliPro Group ...|San Jose, California|0.08093664616821399|\n",
            "|Embedded Systems ...|GCR Professional ...|  Goleta, California|0.07659893476745336|\n",
            "|Embedded Systems ...|      Enphase Energy|       Austin, Texas|0.07594776906368453|\n",
            "|Embedded Systems ...|         CyberCoders|      Eugene, Oregon|0.07497889302584168|\n",
            "|Embedded Systems ...|         CyberCoders|Annapolis Junctio...| 0.0745246835067582|\n",
            "|Embedded Systems ...|            Randstad|Brighton, Massach...|  0.074523565258464|\n",
            "+--------------------+--------------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}